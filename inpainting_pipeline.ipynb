{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMswMiFc792WV4oQGgRHQny",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HLCV-23/Inpainting-Detection/blob/Nicola/inpainting_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Related Work\n",
        "## Inpainting\n",
        "- https://arxiv.org/pdf/2102.12092.pdf  \n",
        "  Dall-e\n",
        "- https://arxiv.org/pdf/2112.10752.pdf  \n",
        "  Stable-Diffusion\n",
        "\n",
        "## GAN-generated images detection\n",
        "- https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8397040  \n",
        "  detection of images generated by GANs, no inpainting\n",
        "- https://arxiv.org/pdf/2202.07145.pdf\n",
        "  review of several GAN detection algorithms\n",
        "\n",
        "## Diffusion-generated images detection\n",
        "- https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10095167  \n",
        "  studies the performance of GAN-detection models on images generated by diffusion models\n",
        "\n",
        "## Inpainting Detection\n",
        "- https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9410590  \n",
        "- https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9506778&tag=1  \n",
        "  similar to our detection approach, but with random(?) masks. It compares the performance on deep learning and traditional inpainting techniques, which might be of interest for us (both for training and evaluation). We could also use the network architecture proposed here. Additional open-source dataset we might want to use.\n",
        "\n",
        "## Image/Network Watermarking\n",
        "- https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=650120  \n",
        "  not directly related, but in watermarking, it is common to test the robustness of image watermarking techniques against common image preprocessing(rescaling, compression, etc). We might want to do that in our experiments too.\n",
        "- https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-adi.pdf\n",
        "- https://tianweiz07.github.io/Papers/21-aamas.pdf  \n",
        "- https://arxiv.org/abs/2305.20030 (Fourier Transform based technique to robustly watermark diffusion model outputs)"
      ],
      "metadata": {
        "id": "Nn-KHr1JKg0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install diffusers\n",
        "!pip install accelerate\n",
        "!pip install xformers\n",
        "import numpy as np\n",
        "from diffusers import StableDiffusionInpaintPipeline\n",
        "from transformers import pipeline\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "from PIL import Image, ImageFilter"
      ],
      "metadata": {
        "id": "dDUvZ3gyKmIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "mask_generator = pipeline(\"mask-generation\", model=\"facebook/sam-vit-huge\", device=device)\n",
        "\n",
        "caption_generator = pipeline(\"image-to-text\", model=\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "\n",
        "prompt_generator = pipeline(\"text-generation\", model= model, tokenizer = tokenizer, device = device)\n",
        "\n",
        "inpainting_model = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-inpainting\",\n",
        "    torch_dtype=torch.float16,\n",
        "    safety_checker=None,\n",
        "    low_cpu_mem_usage = False\n",
        ")"
      ],
      "metadata": {
        "id": "HhNt3vo5Ksg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hugging face token is required to load dataset,\n",
        "# go to https://huggingface.co/datasets/imagenet-1k/viewer/default/train\n",
        "# and get a token in the account settings\n",
        "!pip install datasets\n",
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "ilGNUSk_L7mU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download imagenet or scenes\n",
        "from datasets import load_dataset, Dataset, Image\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "dataset = load_dataset(\"imagenet-1k\", use_auth_token = True, streaming = True, split = \"train\")  # set streaming to false for scenes!\n",
        "dataset = iter(dataset.shuffle())"
      ],
      "metadata": {
        "id": "dGvfbNPQMAIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LnpPUWARMQJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\"\"\"\n",
        "!mkdir drive/MyDrive/Imagenet_Inpainted\n",
        "!touch drive/MyDrive/Imagenet_Inpainted/Prompts.csv\n",
        "!mkdir drive/MyDrive/Imagenet_Inpainted/Images\n",
        "!mkdir drive/MyDrive/Imagenet_Inpainted/Masks\n",
        "!pwd\n",
        "#\"\"\""
      ],
      "metadata": {
        "id": "JXhqYABLMSv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Save original image, save label\n",
        "def generate_datapoint_single_mask(data, id, csv_data, path):\n",
        "    data = data[\"image\"].resize((512,512))\n",
        "    image_area = 512*512\n",
        "    masks = generator(data)[\"masks\"]\n",
        "\n",
        "    # Only masks with an area not too large or too small are eligible candidates for inpainting\n",
        "    valid_masks = [mask for idx, mask in enumerate(masks) if (image_area * 0.025 <= mask.sum() <= image_area * 0.5)]\n",
        "\n",
        "    if (valid_masks != []):\n",
        "      choice = np.random.choice(np.arange(len(valid_masks)))\n",
        "      mask = valid_masks[choice]\n",
        "\n",
        "      mask_img = Image.fromarray((mask * 255).astype(np.uint8).squeeze())\n",
        "      mask_img = mask_img.convert(\"RGB\")\n",
        "\n",
        "      # Generate prompt for inpainting model\n",
        "      caption = image_to_text(data)[0][\"generated_text\"]\n",
        "      prompts = gpt2_pipe(caption)[0][\"generated_text\"]\n",
        "      prompt = prompts.split(\",\")[0]\n",
        "\n",
        "      # inpaint\n",
        "      inpainted_img = pipe(prompt=prompt, image=data, mask_image=mask_img, height=512, width=512).images[0]\n",
        "\n",
        "      # get the edges of the mask\n",
        "      edges = mask_img.filter(ImageFilter.FIND_EDGES).filter(ImageFilter.MaxFilter(7)).convert(\"1\")\n",
        "\n",
        "      # blur the inpainted image\n",
        "      inpainted_img_blur = inpainted_img.filter(ImageFilter.GaussianBlur(radius = 1))\n",
        "\n",
        "      # add the blured parts along the borders of the inpainted object to make it smoother\n",
        "      inpainted_img_smooth = Image.composite(inpainted_img_blur, inpainted_img, edges).convert(\"RGB\")\n",
        "\n",
        "      inpainted_img_smooth.save(path + f\"/Images/{id}.png\")\n",
        "      mask_img.save(path + f\"/Masks/{id}.png\")\n",
        "      csv_data.at[id, \"Prompt\"] = prompt\n",
        "      print(f\"Saved processed image {id}.jpeg\")\n",
        "\n",
        "    else:\n",
        "      print(f\"No valid mask could be generated. Skipping image {id}.\")"
      ],
      "metadata": {
        "id": "LwzYpYYOMYON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"drive/MyDrive/Imagenet_Inpainted\"\n",
        "\n",
        "try:\n",
        "  csv_data = pd.read_csv(path + \"/Prompts.csv\")\n",
        "except:\n",
        "  with open(path + \"/Prompts.csv\", \"w+\") as f:\n",
        "    f.write(\"idx, Prompt\")\n",
        "  csv_data = pd.read_csv(path + \"/Prompts.csv\")\n",
        "\n",
        "for id in range(0,100):\n",
        "    generate_datapoint_single_mask(next(dataset), id, csv_data, path)\n",
        "\n",
        "csv_data.to_csv(path + \"/Prompts.csv\")"
      ],
      "metadata": {
        "id": "JRpfG9tKMbie"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}